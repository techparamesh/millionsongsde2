# Streamify

A data pipeline with Kafka, Spark Streaming, dbt, Docker, Airflow, Terraform, GCP and much more!


## Setup



- Google Cloud Platform. 
- Terraform
  - [Setup Terraform](https://developer.hashicorp.com/terraform/install)




- Procure infra on GCP with Terraform.
- SSH into your VMs, Forward Ports.
- Setup Kafka Compute Instance and start sending messages from Eventsim.
- Setup Spark Cluster for stream processing.
- Setup Airflow on Compute Instance to trigger the hourly data pipeline. 

## Visualisation
-[Looker Studio](https://lookerstudio.google.com/reporting/8f3be2eb-157b-45c5-b86b-fe1a762008d3)
