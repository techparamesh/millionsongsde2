# Streamify

A data pipeline with Kafka, Spark Streaming, dbt, Docker, Airflow, Terraform, GCP and much more!


## Setup



- Google Cloud Platform. 
- Terraform
  - [Setup Terraform](https://developer.hashicorp.com/terraform/install)




- Procure infra on GCP with Terraform.
- SSH into your VMs, Forward Ports.
- Setup Kafka Compute Instance and start sending messages from Eventsim.
- Setup Spark Cluster for stream processing.
- Setup Airflow on Compute Instance to trigger the hourly data pipeline. 

